神经网络的主要工具都在nn（neural network）中：
![[Pasted image 20230707223215.png]]
其中这个类是最重要的：
![[Pasted image 20230707223551.png]]
看一下官网给的示例：

```python
import torch.nn as nn
import torch.nn.functional as F

class Model(nn.Module):
    def __init__(self):
        super().__init__()
        self.conv1 = nn.Conv2d(1, 20, 5)
        self.conv2 = nn.Conv2d(20, 20, 5)

    def forward(self, x):
        x = F.relu(self.conv1(x))
        return F.relu(self.conv2(x))
```
forward是前向传播，
![[Pasted image 20230707224546.png]]就是输入通过前向传播得到输出。
像上面这个例子就是![[Pasted image 20230707224733.png]]
我们每次都应该实现示例中的那两个方法。

# Debug
我们使用debug来看一下神经网络的执行顺序。
代码是这样的：

```python
class TuDui(nn.Module):  
	def __init__(self):  
		super(TuDui, self).__init__()  
	def forward(self, x):  
		output = x+1  
		return output  
  
tudui = TuDui()  
x = torch.tensor(1.0)  
output = tudui(x)  
print(output)
```
当调用 `tudui = TuDui()`  时会去执行`__init__`方法，执行`output = tudui(x)` 时会去执行`forward(self, x)`这个方法。


# 卷积操作

要形象的查看卷积的作用，可以运行这样的代码：

```python
import torch  
import torch.nn.functional as F  
input = torch.tensor([[1, 2, 0,3,1], [0, 1, 2,3,1],[1,2,1,0,0],[5,2,3,1,1],[2,1,0,1,1]])  
  
kernel = torch.tensor([[1,2,1],[0,1,0],[2,1,0]])  
  
input = torch.reshape(input,[1,1,5,5])  
kernel = torch.reshape(kernel,[1,1,3,3])  
output = F.conv2d(input, kernel, stride=1)  
print(input.shape)  
print(kernel.shape)  
print(output)
```
![[Pasted image 20230707232854.png]]

设置padding为1是这样的：

```python
output2 = F.conv2d(input, kernel, stride=1,padding=1)
```

![[Pasted image 20230707233117.png]]


# Conv2d
这是用于2D图像的卷积核。
构造参数有如下：

```python
import torch.nn as nn

conv = nn.Conv2d(in_channels=3, 
                 out_channels=64, 
                 kernel_size=(3, 3), 
                 stride=(1, 1), 
                 padding=(1, 1), 
                 padding_mode='reflect', 
                 dilation=(1, 1), 
                 groups=1, 
                 bias=True)
```
- 输入图像有3个通道（例如，RGB图像）
- 卷积将产生64个输出通道
- 卷积核的大小是3x3
- 卷积的步长是1x1（在每个方向上移动1个像素）
- 在所有四侧添加1像素的填充，填充模式为'reflect'
- 核元素之间的间距是1x1，空洞卷积
- 输入通道到输出通道的阻塞连接数是1,几乎不用
- 向输出添加可学习的偏置
只有前三个是自己必须设置的。空洞卷积是这样的，卷积核每个元素之间空几个位置：
![[dilation.gif]]

输入channel和输出channel的理解：
![[Pasted image 20230707234335.png]]
输入的图像只有一层，所以是1，输出如果设置为2时，会多创建一个卷积核（参数和原来不一致）再产生一层输出得到channel为2的输出

# MaxPool2d
这是2D的最大池化层，细致可看官网[MaxPool2d — PyTorch 2.0 documentation](https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html#torch.nn.MaxPool2d)

构造参数有这些：
  
kernel_size（Union[int, Tuple[int, int]]）– 用于取最大值的窗口大小
stride（Union[int, Tuple[int, int]]）– 窗口的步长。默认值是kernel_size
padding（Union[int, Tuple[int, int]]）– 在两侧添加的隐式负无穷大填充
dilation（Union[int, Tuple[int, int]]）– 控制窗口中元素步长的参数
return_indices（bool）– 如果为True，将返回最大索引和输出。对于torch.nn.MaxUnpool2d后面有用
ceil_mode（bool）– 当为True时，将使用ceil而不是floor来计算输出形状
简单来说就是形状不满时，ceil会计算池化，floor不会计算池化
![[Pasted image 20230708094406.png]]
可以测试一下，如下代码：

```python
import torch  
from torch import nn  
from torch.nn import MaxPool2d  
  
input =torch.tensor([[1,2,0,3,1],[0,1,2,3,1],[1,2,1,0,0],[5,2,3,1,1],[2,1,0,1,1]],dtype=torch.float32)  
  
input = torch.reshape(input,[1,5,5])  
class TuDui(nn.Module):  
	def __init__(self):  
		super(TuDui,self).__init__()  
		self.MaxPool1 = MaxPool2d(kernel_size=3, ceil_mode=True)  
	def forward(self,x):  
		output = self.MaxPool1(x)  
		return output  
print(input)  
tudui = TuDui()  
output = tudui(input)  
print(output)
```
打印是这样的：
![[Pasted image 20230708102048.png]]
与上图相符
但是将ceil_mode修改成False，就变成了：
![[Pasted image 20230708102331.png]]
与图都符合。


# 非线性激活
比较常用的是RELU,[ReLU — PyTorch 2.0 documentation](https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html#torch.nn.ReLU)
![[Pasted image 20230708113445.png]]
构造参数只有一个 ，
Parameters:
**inplace** – can optionally do the operation in-place. Default: `False`

inplace如果为True，那么会对输入的tensor进行修改，如果False，那么生成一个拷贝进行修改。
使用如下代码进行测试：

```python
import torch  
from torch import nn  
  
input = torch.tensor([[-1, 2, 3], [-4, -5, -6]])  
  
class TuDui(nn.Module):  
	def __init__(self):  
		super(TuDui, self).__init__()  
		self.Relu = nn.ReLU(False)  
	def forward(self, x):  
		x = self.Relu(x)  
		return x  
  
TuDui = TuDui()  
print("输入原先是： ")  
print(input)  
output = TuDui(input)  
print("通过RELU后的input")  
print(input)  
print("output")  
print(output)
```
这里设置是False，结果如下
![[Pasted image 20230708114534.png]]
如果设置成True，就变成了：
![[Pasted image 20230708114623.png]]
## 基础使用
上面只是测试，接下来是基础使用

```python
  
import torch  
import torchvision  
from torch import nn  
from torch.utils.tensorboard import SummaryWriter  
  
dataset = torchvision.datasets.CIFAR10(root='./data', train=False,download=True,transform=torchvision.transforms.ToTensor())  
dataloader = torch.utils.data.DataLoader(dataset, batch_size=64)  
  
class TuDui(nn.Module):  
	def __init__(self):  
		super(TuDui, self).__init__()  
		self.Relu = nn.ReLU(False)  
		self.sigmoid = nn.Sigmoid()  
	def forward(self, x):  
		x = self.sigmoid(x)  
		return x  
  
TuDui = TuDui()  
step = 0  
writer = SummaryWriter("logs_RELU")  
for data in dataloader:  
	img_input,target = data  
	img_output = TuDui(img_input)  
	writer.add_images("input",img_input,step)  
	writer.add_images("output",img_output,step)  
	step+=1  
writer.close()
```
然后使用 `tensorboard --logdir=logs_RELU`查看
![[Pasted image 20230708123805.png]]
非线性激活效果如上。



# SEQUENTIAL
这个方法比nn.module会更简单一些。

使用：
```python
from torch import nn

# 定义一个包含两个全连接层的模型
model = nn.Sequential(
    nn.Linear(10, 5),  # 输入层大小为10，输出层大小为5
    nn.ReLU(),  # 激活函数
    nn.Linear(5, 2),  # 输入层大小为5，输出层大小为2
)

# 可以像使用常规PyTorch模型那样使用这个模型
# 假设我们有一个大小为(32, 10)的输入（批量大小为32）
input = torch.randn(32, 10)
output = model(input)  # 输出将会是大小为(32, 2)的张量

```
或者：

```python
class MyModel(nn.Module):
    def __init__(self):
        super(MyModel, self).__init__()

        self.model = nn.Sequential(
            nn.Linear(10, 5),
            nn.ReLU(),
            nn.Linear(5, 2)
        )

    def forward(self, x):
        return self.model(x)
model = MyModel()
input = torch.randn(32, 10)
output = model(input)  # 输出将会是大小为(32, 2)的张量

```


# 损失函数
主要都在这里 [torch.nn — PyTorch 2.0 documentation](https://pytorch.org/docs/stable/nn.html#loss-functions)

然后损失函数中 有一个backward()方法，可以计算梯度，后面使用优化器就能降低loss。
基本使用：

```python
import torch  
import torchvision  
from torch import nn  
from torch.nn import Sequential, Conv2d, MaxPool2d, Flatten, Linear  
  
dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform = torchvision.transforms.ToTensor())  
  
dataloader = torch.utils.data.DataLoader(dataset, batch_size=1)  
  
class TuDui(nn.Module):  
	def __init__(self):  
		super(TuDui, self).__init__()  
		self.model1 = Sequential(  
			Conv2d(3, 32, 5, padding=2),  
			MaxPool2d(2),  
			Conv2d(32, 32, 5, padding=2),  
			MaxPool2d(2),  
			Conv2d(32, 64, 5, padding=2),  
			MaxPool2d(2),  
			Flatten(),  
			Linear(1024,64),  
			Linear(64,10)  
		)  
	  
	def forward(self, x):  
		x=self.model1(x)  
		return x  
  
loss = nn.CrossEntropyLoss()  
tudui = TuDui()  
for data in dataloader:  
imgs ,target =data  
output = tudui(imgs)  
# print(output)  
# print(target)  
result_loss = loss(output, target)  
result_loss.backward()  
print(result_loss)

```


## L1 Loss
L1Loss是基于绝对误差的。它计算了每个元素位置上的目标值与输入值之间的差的绝对值。

## MSELOSS
MSE（Mean Squared Error）Loss，也被称为均方误差损失函数，是一种常用的回归损失函数。它的计算公式为![[Pasted image 20230708141843.png]]

## 交叉熵损失CROSSENTROPYLOSS
是一种常用的**分类**损失函数
![[Pasted image 20230708142508.png]]



# 优化器

官网的地址： [torch.optim — PyTorch 2.0 documentation](https://pytorch.org/docs/stable/optim.html)
主要是有SGD和Adam两种方式。

构造是这样的： 

```python
optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)
```

使用如下：

```python
for input, target in dataset:
    # 在每次迭代开始时，将优化器中的梯度清零。这是因为默认情况下，每当调用.backward()时，梯度就会在缓冲区中累积，所以我们需要手动将其清零。
    optimizer.zero_grad()
    # 将输入数据传入模型，进行前向传播，得到输出结果
    output = model(input)
    # 计算模型输出和目标值之间的损失
    loss = loss_fn(output, target)
    # 对损失进行反向传播，即计算损失函数对模型参数的梯度
    loss.backward()
    # 使用优化器更新模型参数，进行一步优化
    optimizer.step()

```











