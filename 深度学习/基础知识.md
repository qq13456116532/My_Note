使用pytorch

```python
import torch
```


# 张量
张量表示一个由数值组成的数组，这个数组可能有多个维度。 具有**一个轴**的张量对应数学上的**向量**（vector）； 具有**两个轴**的张量对应数学上的**矩阵**（matrix）


## 行向量

### 连续整数
```python
x = torch.arange(12)
```
张量将存储在内存中，并采用基于CPU的计算。
![](images/Pasted%20image%2020230719091252.png)

### 形状

```python
x.shape
```


### 元素总数

```python
x.numel()
```

### 改变形状

```python
X = x.reshape(3, 4)
```
但是也可以不用指定高度和宽度，指定其中一个也是可以的。
我们可以通过`-1`来调用此自动计算出维度的功能。 即我们可以用

```python
x.reshape(-1,4)
```
或者
```python
x.reshape(3,-1)
```

来取代`x.reshape(3,4)`

### 特定常量

```python
torch.zeros((2, 3, 4))
torch.ones((2, 3, 4))
# 从均值为0、标准差为1的标准高斯分布（正态分布）中随机采样
torch.randn(3, 4)
```



## 运算符
对于任意具有相同形状的张量， 常见的标准算术运算符（`+`、`-`、`*`、`/`和`**`）都可以被升级为按元素运算

如

```python
x =  torch.arange(12)
y =  torch.arange(12)
z=x+y
```
![](images/Pasted%20image%2020230719092432.png)

### 求冥

```python
ez = torch.exp(z)
```


### 连结（concatenate）
把多个张量_连结_（concatenate）在一起， 把它们端对端地叠起来形成一个更大的张量。 我们只需要提供张量列表，并给出沿哪个轴连结。 下面的例子分别演示了当我们沿行（轴-0，形状的第一个元素） 和按列（轴-1，形状的第二个元素）连结两个矩阵时，会发生什么情况
![](images/Pasted%20image%2020230719092845.png)
和
![](images/Pasted%20image%2020230719092915.png)


### 求和

```python
sumx = torch.sum(x)
```
![](images/Pasted%20image%2020230719093353.png)

## 广播机制
在某些情况下，即使形状不同，我们仍然可以通过调用 _广播机制_（broadcasting mechanism）来执行按元素操作
1. 通过适当复制元素来扩展一个或两个数组，以便在转换之后，两个张量具有相同的形状；
2. 对生成的数组执行按元素操作。
比如![](images/Pasted%20image%2020230719094713.png)两个相加
就会得到
![](images/Pasted%20image%2020230719094755.png)

### 索引和切片
第一个元素的索引是0，最后一个元素索引是-1； 可以指定范围以包含第一个元素和最后一个之前的元素。

```python
X[-1], X[1:3]
```
多个元素赋值相同的值，我们只需要索引所有元素，然后为它们赋值

```python
X[0:2, :] = 12
```



###  torch张量和numpy数组转换

```python
A = X.numpy()
B = torch.tensor(A)
```

大小为1的张量转换为Python标量，我们可以调用`item`函数

```python
a = torch.tensor([3.5])
a, a.item(),
```



# Pandas数据预处理

## 创建数据集
为了测试相关代码，自己创建一个数据集

```python
import os

  
os.makedirs(os.path.join('.', 'data'), exist_ok=True)
data_file = os.path.join('.', 'data', 'house_tiny.csv')
with open(data_file, 'w') as f:

    f.write('NumRooms,Alley,Price\n')  # 列名

    f.write('NA,Pave,127500\n')  # 每行表示一个数据样本

    f.write('2,NA,106000\n')

    f.write('4,NA,178100\n')

    f.write('NA,NA,140000\n')
```


## 读取

```python
import pandas as pd  
import os  
  
data_file = os.path.join('.', 'data', 'house_tiny.csv')  
  
data = pd.read_csv(data_file)  
print(data)
```
![](images/Pasted%20image%2020230719121011.png)
其中的NaN是指空缺的值，**为了处理缺失的数据，典型的方法包括插值法和删除法，** 其中插值法用一个替代值弥补缺失值，而删除法则直接忽略缺失值

```python
# 使用Pandas的 `iloc` 函数选取DataFrame中的特定数据
# `data.iloc[:, 0:2]` 选取所有行的前两列数据
# `data.iloc[:, 2]` 选取所有行的第三列数据
inputs, outputs = data.iloc[:, 0:2], data.iloc[:, 2]

# 使用 `fillna` 方法处理在 `inputs` 中存在的缺失值（NaN）
# `inputs.mean()` 计算 `inputs` 的每一列的平均值
# `fillna` 使用这些平均值填充对应列的缺失值
inputs = inputs.fillna(inputs.mean())

# 打印 `inputs` 的值
print(inputs)

# 使用Pandas的 `get_dummies` 函数对类别变量进行"One-Hot"编码
# `dummy_na=True` 指明如果存在缺失值NaN也进行One-Hot编码
inputs = pd.get_dummies(inputs, dummy_na=True)

# 打印经过填充缺失值，并进行One-Hot编码后的 `inputs` 的值
print(inputs)

```
经过处理，数据变成：
![](images/Pasted%20image%2020230719122737.png)
![](images/Pasted%20image%2020230719122746.png)


## 转换成张量

```python
import torch
X, y = torch.tensor(inputs.values), torch.tensor(outputs.values)
```


##  向量
向量可以被视为标量值组成的列表。 这些标量值被称为向量的*元素*（element）或*分量*（component）
人们通过一维张量表示向量。一般来说，张量可以具有任意长度，取决于机器的内存限制。
![](images/Pasted%20image%2020230719124529.png)
在代码中，我们通过张量的索引来访问任一元素。

```python
x[3]
```


### 长度和形状

```python
len(x)
x.shape
```
![](images/Pasted%20image%2020230719125503.png)

## 矩阵
正如向量将标量从零阶推广到一阶，矩阵将向量从一阶推广到二阶

```python
A = torch.arange(20).reshape(5, 4)
```

### 矩阵的转置

```python
A.T
```
### 矩阵的按元素乘法
两个矩阵的按元素乘法称为*Hadamard积*（Hadamard product）（数学符号⊙）

```python
B = A.clone()  # 通过分配新内存，将A的一个副本分配给B

A * B
```

## 降维


### 求和
对任意张量进行的一个有用的操作是计算其元素的和

```python
x = torch.arange(4, dtype=torch.float32)
y=x.sum()
```

默认情况下，调用求和函数会沿所有的轴降低张量的维度，使它变为一个标量。 我们还可以指定张量沿哪一个轴来通过求和降低维度。 以矩阵为例，为了通过求和所有行的元素来降维（轴0），可以在调用函数时指定`axis=0`。 由于输入矩阵沿0轴降维以生成输出向量，因此输入轴0的维数在输出形状中消失。
指定`axis=1`将通过汇总所有列的元素降维（轴1）。因此，输入轴1的维数在输出形状中消失。

```python
A_sum_axis1 = A.sum(axis=1)
```

还有对多个轴一起

```python
A.sum(axis=[0, 1])
```




### _平均值_

```python
A.mean()
```

```python
A.mean(axis=0)
```


### 保持维数

```python
A = torch.arange(20).reshape(5, 4)
sum_A = A.sum(axis=1, keepdims=True)
```
还是保持和A一样的维数，而不是变成一个行向量。
![](images/Pasted%20image%2020230719155243.png)

### 累积求和
沿某个轴计算`A`元素的累积总和， 比如`axis=0`（按行计算），可以调用`cumsum`函数。 此函数不会沿任何轴降低输入张量的维度。
```python
A.cumsum(axis=0)
```
![](images/Pasted%20image%2020230719155832.png)

## 点积
点积是相同位置的按元素乘积的和


```python
y = torch.ones(4, dtype = torch.float32)
torch.dot(x, y)
```


## _矩阵-向量积_
_矩阵-向量积_（matrix-vector product），![](images/Pasted%20image%2020230719160312.png)
接收两个参数：一个二维矩阵和一个一维向量，**只能用于二维矩阵和一维向量**
代码如下：

```python
import torch  

# 创建一个 2x3 的矩阵  
mat = torch.ones(2, 3)  
  
# 创建一个长度为 3 的向量  
vec = torch.ones(3)  
  
# 使用 torch.mv 计算矩阵与向量的乘积  
output = torch.mv(mat, vec)
```
![](images/Pasted%20image%2020230719163948.png)


## **矩阵-矩阵乘法**

这个就是简单的矩阵乘法。

```python
A = torch.ones(3,2)  
B = torch.ones(2,3)  
torch.mm(A, B)
```

![](images/Pasted%20image%2020230719164150.png)


## 范数
L1范数： ![](images/Pasted%20image%2020230719164458.png)，向量元素的绝对值之和

```python
torch.abs(u).sum()
```

![](images/Pasted%20image%2020230719164617.png)

L2范数： ![](images/Pasted%20image%2020230719164508.png)，是向量元素平方和的平方根

```python
u = torch.tensor([3.0, -4.0])
torch.norm(u)
```
![](images/Pasted%20image%2020230719164600.png)


  
L2范数和L1范数都是更一般的L<sub>p</sub>范数的特例
![](images/Pasted%20image%2020230719164707.png)



#  自动微分
深度学习框架通过自动计算导数，即自动微分（automatic differentiation）来加快求导 。实际中，根据设计好的模型，系统会构建一个**计算图**（computational graph）， 来跟踪计算是哪些数据通过哪些操作组合起来产生输出。 自动微分使系统能够随后反向传播梯度。 这里，_反向传播_（backpropagate）意味着跟踪整个计算图，填充关于每个参数的偏导数。

```python
import torch  
  
x = torch.arange(4.0)  
x.requires_grad_(True)
```
开启x的自动梯度计算
此时打印
```python
print(x.grad)
```
为None
计算y
```python
y = 2 * torch.dot(x, x)
```
调用反向传播函数来自动计算`y`关于`x`每个分量的梯度，并打印这些梯度
```python
y.backward()  
print(x.grad)
```
$y=2\mathbf{x}^{\top}\mathbf{x}$公式是这样的，所以对于(0,1,2,3)应该 *4 ，变成(0,4,8,12)
![](images/Pasted%20image%2020230719192512.png)

然后计算其他梯度的时候，需要清空当前梯度：

```python
# 在默认情况下，PyTorch会累积梯度，我们需要清除之前的值  
x.grad.zero_()  
y = x.sum()  
y.backward()  
x.grad
```
![](images/Pasted%20image%2020230719192613.png)


## 分离计算
有时会出现这样的情况 ：
z =x * y ，y=x^2
我们想计算`z`关于`x`的梯度，但由于某种原因，希望将`y`视为一个常数， 并且只考虑到`x`在`y`被计算后发挥的作用。
这里可以分离`y`来返回一个新变量`u`，该变量与`y`具有相同的值， 但丢弃计算图中如何计算`y`的任何信息。 换句话说，梯度不会向后流经`u`到`x`。 因此，下面的反向传播函数计算`z=u*x`关于`x`的偏导数，同时将`u`作为常数处理， 而不是`z=x*x*x`关于`x`的偏导数。

```python
x = torch.arange(4.0)  
x.requires_grad_(True)  
# x.grad.zero_()  
y = x * x  
u = y.detach()  
z = u * x  
  
z.sum().backward()  
print(u)  
x.grad
```
![](images/Pasted%20image%2020230719193757.png)
可以看到得到的值就是u的值，而不是x^3去求导了。



# 线性神经网络

## 随机梯度下降
_梯度下降_（gradient descent几乎可以优化所有深度学习模型。 它通过不断地在损失函数递减的方向上更新参数来降低误差。
梯度下降最简单的用法是计算损失函数（数据集中所有样本的损失均值） 关于模型参数的导数（在这里也可以称为梯度）。 但实际中的执行可能会非常慢：因为在每一次更新参数之前，我们必须**遍历整个数据集**。 因此，我们通常会在每次需要计算更新的时候随机抽取一小批样本， 这种变体叫做**小批量随机梯度下降**（minibatch stochastic gradient descent）。

在每次迭代中，我们首先随机抽样一个小批量$\mathcal{B}$， 它是由固定数量的训练样本组成的。 然后，我们计算小批量的平均损失关于模型参数的导数（也可以称为梯度）。 最后，我们将梯度乘以一个预先确定的正数$\eta$，并从当前参数的值中减掉。
$(\mathbf{w},b) \leftarrow (\mathbf{w},b) - \frac{\eta}{|\mathcal{B}|} \sum_{i \in \mathcal{B}} \partial_{(\mathbf{w},b)} l^{(i)}(\mathbf{w},b).$
- $|\mathcal{B}|$表示每个小批量中的样本数，这也称为_批量大小_（batch size）
- $\eta$表示_学习率_（learning rate）
上面这种可以调整但不在训练过程中更新的参数称为**超参数**（hyperparameter）



### 基础代码

```python
# nn是神经网络的缩写
from torch import nn

net = nn.Sequential(nn.Linear(2, 1))
loss = nn.MSELoss()
trainer = torch.optim.SGD(net.parameters(), lr=0.03)
num_epochs = 3
for epoch in range(num_epochs):
    for X, y in data_iter:
        l = loss(net(X) ,y)
        trainer.zero_grad()
        l.backward()
        trainer.step()
    l = loss(net(features), labels)
    print(f'epoch {epoch + 1}, loss {l:f}')


```


# 分类问题
一般的分类问题并不与类别之间的自然顺序有关。 幸运的是，统计学家很早以前就发明了一种表示分类数据的简单方法：**_独热编码_**（one-hot encoding）。 独热编码是一个向量，它的分量和类别一样多。 类别对应的分量设置为1，其他所有分量设置为0。
我们从一个图像分类问题开始。 假设每次输入是一个2×2的灰度图像。 我们可以用一个标量表示每个像素值，每个图像对应四个特征$x_1, x_2, x_3, x_4$。 此外，假设每个图像属于类别“猫”“鸡”和“狗”中的一个。 此时，标签 $y$ 将是一个三维向量,$(1, 0, 0)$是猫，$(0, 1, 0)$是鸡，$(0, 0, 1)$ 是狗。
像这种问题基本就是要用到这样的神经网络：
![](images/Pasted%20image%2020230719235415.png)
## SoftMax函数
因为想要保证三个输出加起来是1，而且非负，而且可导，所以发明了softmax函数，
softmax函数能够将未规范化的预测变换为非负数并且总和为1，同时让模型保持 可导的性质。 为了完成这一目标，我们首先对每个未规范化的预测求幂，这样可以确保输出非负。 为了确保最终输出的概率值总和为1，我们再让每个求幂后的结果除以它们的总和。如下式：
![](images/Pasted%20image%2020230719235716.png)

像这种分类问题的损失函数也是用*交叉熵损失*
![](images/Pasted%20image%2020230720114510.png)


## Fashion-MNIST数据集
Fashion-MNIST是一个服装分类数据集，由10个类别的图像组成。在后续章节中使用此数据集来评估各种分类算法。
导包：

```python
%matplotlib inline
import torch  
import torchvision  
from torch.utils import data  
from torchvision import transforms  
from d2l import torch as d2l  
  
d2l.use_svg_display()
```

从网络中下载

```python
# 通过ToTensor实例将图像数据从PIL类型变换成32位浮点数格式，  
# 并除以255使得所有像素的数值均在0～1之间  
trans = transforms.ToTensor()  
mnist_train = torchvision.datasets.FashionMNIST(  
root="../data", train=True, transform=trans, download=True)  
mnist_test = torchvision.datasets.FashionMNIST(  
root="../data", train=False, transform=trans, download=True)
print(len(mnist_train))  
print(len(mnist_test))
```

每个输入图像的高度和宽度均为28像素。 数据集由灰度图像组成，其通道数为1。 为了简洁起见，高度ℎ像素、宽度w像素图像的形状记为ℎ×w或（ℎ,w）。
Fashion-MNIST中包含的10个类别，分别为t-shirt（T恤）、trouser（裤子）、pullover（套衫）、dress（连衣裙）、coat（外套）、sandal（凉鞋）、shirt（衬衫）、sneaker（运动鞋）、bag（包）和ankle boot（短靴）。 以下函数用于在数字标签索引及其文本名称之间进行转换。

```python
def get_fashion_mnist_labels(labels):  #@save
    """返回Fashion-MNIST数据集的文本标签"""
    text_labels = ['t-shirt', 'trouser', 'pullover', 'dress', 'coat',
                   'sandal', 'shirt', 'sneaker', 'bag', 'ankle boot']
    return [text_labels[int(i)] for i in labels]
```
然后把一批图片显示出来:

```python
def show_images(imgs, num_rows, num_cols, titles=None, scale=1.5):  #@save
    """绘制图像列表"""
    figsize = (num_cols * scale, num_rows * scale)
    _, axes = d2l.plt.subplots(num_rows, num_cols, figsize=figsize)
    axes = axes.flatten()
    for i, (ax, img) in enumerate(zip(axes, imgs)):
        if torch.is_tensor(img):
            # 图片张量
            ax.imshow(img.numpy())
        else:
            # PIL图片
            ax.imshow(img)
        ax.axes.get_xaxis().set_visible(False)
        ax.axes.get_yaxis().set_visible(False)
        if titles:
            ax.set_title(titles[i])
    return axes
X, y = next(iter(data.DataLoader(mnist_train, batch_size=18)))
show_images(X.reshape(18, 28, 28), 2, 9, titles=get_fashion_mnist_labels(y));
```
画出这样的图片： ![](images/Pasted%20image%2020230720210102.png)



### 整合组件
`load_data_fashion_mnist`函数，用于获取和读取Fashion-MNIST数据集。 这个函数返回训练集和验证集的数据迭代器。 此外，这个函数还接受一个可选参数`resize`，用来将图像大小调整为另一种形状。

```python
def get_dataloader_workers():  #@save
    """使用4个进程来读取数据"""
    return 4

def load_data_fashion_mnist(batch_size, resize=None):  #@save
    """下载Fashion-MNIST数据集，然后将其加载到内存中"""
    trans = [transforms.ToTensor()]
    if resize:
        trans.insert(0, transforms.Resize(resize))
    trans = transforms.Compose(trans)
    mnist_train = torchvision.datasets.FashionMNIST(
        root="../data", train=True, transform=trans, download=True)
    mnist_test = torchvision.datasets.FashionMNIST(
        root="../data", train=False, transform=trans, download=True)
    return (data.DataLoader(mnist_train, batch_size, shuffle=True,
                            num_workers=get_dataloader_workers()),
            data.DataLoader(mnist_test, batch_size, shuffle=False,
                            num_workers=get_dataloader_workers()))

```














# _多层感知机_（multilayer perceptron）
将许多全连接层堆叠在一起。 每一层都输出到上面的层，直到生成最后的输出。 我们可以把前$L-1$层看作表示，把最后一层看作线性预测器。 这种架构通常称为_多层感知机_（multilayer perceptron），通常缩写为_MLP_。

![](images/Pasted%20image%2020230720212918.png)
这个多层感知机有4个输入，3个输出，其隐藏层包含5个隐藏单元。 输入层不涉及任何计算，因此使用此网络产生输出只需要实现隐藏层和输出层的计算。 因此，这个多层感知机中的层数为2。 注意，这两个层都是**全连接**的。 每个输入都会影响隐藏层中的每个神经元， 而隐藏层中的每个神经元又会影响输出层中的每个神经元。



# 多层感知机


## 激活函数

 多层感知机在输出层和输入层之间增加一个或多个全连接隐藏层，并通过激活函数转换隐藏层的输出。
### ReLU函数
$\operatorname{ReLU}(x) = \max(x, 0).$
![](images/Pasted%20image%2020230720224309.png)

### sigmoid函数
$\operatorname{sigmoid}(x) = \frac{1}{1 + \exp(-x)}.$
![](images/Pasted%20image%2020230720224337.png)
### tanh函数

$\operatorname{tanh}(x) = \frac{1 - \exp(-2x)}{1 + \exp(-2x)}.$
![](images/Pasted%20image%2020230720224400.png)



### $K$折交叉验证

当训练数据稀缺时，我们甚至可能无法提供足够的数据来构成一个合适的验证集。 这个问题的一个流行的解决方案是采用$K$折交叉验证。 这里，原始训练数据被分成$K$个不重叠的子集。 然后执行$K$次模型训练和验证，每次在$K$−1个子集上进行训练， 并在剩余的一个子集（在该轮中没有用于训练的子集）上进行验证。 最后，通过对$K$次实验的结果取平均来估计训练和验证误差。





### _权重衰减_（weight decay）
_权重衰减_（weight decay）是最广泛使用的正则化的技术之一， 它通常也被称为L2_正则化_。 这项技术通过函数与零的距离来衡量函数的复杂度， 因为在所有函数f中，函数f=0（所有输入都得到值0） 在某种意义上是最简单的。
我们的损失由下式给出：
$L(\mathbf{w}, b) = \frac{1}{n}\sum_{i=1}^n \frac{1}{2}\left(\mathbf{w}^\top \mathbf{x}^{(i)} + b - y^{(i)}\right)^2.$
$(\mathbf{w}, b)$  是权重和偏置参数,为了惩罚权重向量的大小， 我们必须以某种方式在损失函数中添加$\| \mathbf{w} \|^2$， 但是模型应该如何平衡这个新的额外惩罚的损失？ 实际上，我们通过_正则化常数$\lambda$来描述这种权衡， 这是一个非负超参数，我们使用验证数据拟合：
![](images/Pasted%20image%2020230720231506.png)
当我们取一个二次函数的导数时， 2和1/2会抵消，以确保更新表达式看起来既漂亮又简单。
使用L2范数的一个原因是它对权重向量的大分量施加了巨大的惩罚。 这使得我们的学习算法偏向于在大量特征上均匀分布权重的模型。 在实践中，这可能使它们对单个变量中的观测误差更为稳定。 相比之下，L1惩罚会导致模型将权重集中在一小部分特征上， 而将其他权重清除为零。 这称为***特征选择***（feature selection），这可能是其他场景下需要的。
$L_2$正则化回归的小批量随机梯度下降更新如下式：
![](images/Pasted%20image%2020230720231734.png)



### 暂退法（Dropout）
 暂退法在前向传播过程中，计算每一内部层的同时注入噪声，这已经成为训练神经网络的常用技术。 这种方法之所以被称为_暂退法_，因为我们从表面上看是在训练过程中丢弃（drop out）一些神经元。 在整个训练过程的每一次迭代中，标准暂退法包括在计算下一层之前将当前层中的一些节点置零。

需要说明的是，暂退法的原始论文提到了一个关于有性繁殖的类比： 神经网络过拟合与每一层都依赖于前一层激活值相关，称这种情况为“共适应性”。 作者认为，暂退法会破坏共适应性，就像有性生殖会破坏共适应的基因一样。


### 梯度消失
不稳定梯度带来的风险不止在于数值表示； 不稳定梯度也威胁到我们优化算法的稳定性。 我们可能面临一些问题。 要么是_梯度爆炸_（gradient exploding）问题： 参数更新过大，破坏了模型的稳定收敛； 要么是_梯度消失_（gradient vanishing）问题： 参数更新过小，在每次更新时几乎不会移动，导致模型无法学习。
![](images/Pasted%20image%2020230720234129.png)
正如上图，当sigmoid函数的输入很大或是很小时，它的梯度都会消失。 此外，当反向传播通过许多层时，除非我们在刚刚好的地方， 这些地方sigmoid函数的输入接近于零，否则整个乘积的梯度可能会消失。 当我们的网络有很多层时，除非我们很小心，否则在某一层可能会切断梯度。 事实上，这个问题曾经困扰着深度网络的训练。 因此，更稳定的ReLU系列函数已经成为从业者的默认选择（虽然在神经科学的角度看起来不太合理）。



# 深度学习计算
到目前为止，我们一直在通过`net(X)`调用我们的模型来获得模型的输出。 这实际上是`net.__call__(X)`的简写。 这个前向传播函数非常简单： 它将列表中的每个块连接在一起，将每个块的输出作为下一个块的输入。

## 访问参数
通过`Sequential`类定义模型时， 我们可以通过索引来访问模型的任意层。 这就像模型是一个列表一样，每层的参数都在其属性中

```python
from torch import nn

net = nn.Sequential(nn.Linear(4, 8), nn.ReLU(), nn.Linear(8, 1))
print(net[2].state_dict())
```
检查第二个全连接层的参数
![](images/Pasted%20image%2020230721180104.png)
这个全连接层包含两个参数，分别是该层的权重和偏置

或者这样访问具体参数：

```python
print(type(net[2].bias))
print(net[2].bias)
print(net[2].bias.data)
```

##  参数初始化 
深度学习框架提供默认随机初始化， 也允许我们创建自定义初始化方法， 满足我们通过其他规则实现初始化权重。
将所有权重参数初始化为标准差为0.01的高斯随机变量， 且将偏置参数设置为0：
```python
net = nn.Sequential(nn.Linear(4, 8), nn.ReLU(), nn.Linear(8, 1))
def init_normal(m):
    if type(m) == nn.Linear:
        nn.init.normal_(m.weight, mean=0, std=0.01)
        nn.init.zeros_(m.bias)
net.apply(init_normal)
net[0].weight.data[0], net[0].bias.data[0]
```
![](images/Pasted%20image%2020230721182205.png)

所有参数初始化为给定的常数，比如初始化为1：
```python
net = nn.Sequential(nn.Linear(4, 8), nn.ReLU(), nn.Linear(8, 1))
def init_constant(m):
    if type(m) == nn.Linear:
        nn.init.constant_(m.weight, 1)
        nn.init.zeros_(m.bias)
net.apply(init_constant)
net[0].weight.data[0], net[0].bias.data[0]
```
![](images/Pasted%20image%2020230721182246.png)

还可以对不同块应用不同的初始化方法

```python
net = nn.Sequential(nn.Linear(4, 8), nn.ReLU(), nn.Linear(8, 1))
def init_xavier(m):
    if type(m) == nn.Linear:
        nn.init.xavier_uniform_(m.weight)
def init_42(m):
    if type(m) == nn.Linear:
        nn.init.constant_(m.weight, 42)

net[0].apply(init_xavier)
net[2].apply(init_42)
print(net[0].weight.data[0])
print(net[2].weight.data)
```

## 参数绑定
在多个层间共享参数： 我们可以定义一个稠密层，然后使用它的参数来设置另一个层的参数

```python
# 我们需要给共享层一个名称，以便可以引用它的参数
shared = nn.Linear(8, 8)
net = nn.Sequential(nn.Linear(4, 8), nn.ReLU(),
                    shared, nn.ReLU(),
                    shared, nn.ReLU(),
                    nn.Linear(8, 1))
net(X)
# 检查参数是否相同
print(net[2].weight.data[0] == net[4].weight.data[0])
net[2].weight.data[0, 0] = 100
# 确保它们实际上是同一个对象，而不只是有相同的值
print(net[2].weight.data[0] == net[4].weight.data[0])
```
修改后也不改变相同
![](images/Pasted%20image%2020230721182617.png)


#  读写文件
## 加载和保存张量
对于单个张量，我们可以直接调用`load`和`save`函数分别读写它们。 这两个函数都要求我们提供一个名称，`save`要求将要保存的变量作为输入

```python
import torch
from torch import nn
from torch.nn import functional as F

x = torch.arange(4)
torch.save(x, 'x-file')
x2 = torch.load('x-file')
```

也可以变成列表存储

```python
y = torch.zeros(4)
torch.save([x, y],'x-files')
x2, y2 = torch.load('x-files')

```

也可以存储字典张量

```python
mydict = {'x': x, 'y': y}
torch.save(mydict, 'mydict')
mydict2 = torch.load('mydict')
```


## 加载和保存模型参数

```python
torch.save(net.state_dict(), 'mlp.params')
```

和

```python
clone = MLP()
clone.load_state_dict(torch.load('mlp.params'))
clone.eval()
```

# GPU
 如果有多个GPU，我们使用`torch.device(f'cuda:{i}')` 来表示第�块GPU（�从0开始）。 另外，`cuda:0`和`cuda`是等价的。

```python
import torch
from torch import nn

torch.device('cpu'), torch.device('cuda'), torch.device('cuda:1')
```
可以查询可用gpu的数量

```python
torch.cuda.device_count()
```

## 张量与GPU

我们可以查询张量所在的设备。 默认情况下，张量是在CPU上创建的。无论何时我们要对多个项进行操作， 它们都必须在同一个设备上。 例如，如果我们对两个张量求和， 我们需要确保两个张量都位于同一个设备上， 否则框架将不知道在哪里存储结果，甚至不知道在哪里执行计算。
有几种方法可以在GPU上存储张量。 例如，我们可以在创建张量时指定存储设备

```python
import torch  
X = torch.ones(2, 3, device=torch.device('cuda'))  
X
```
![](images/Pasted%20image%2020230721190742.png)



### 复制
如果两个张量不在一个GPU上，直接相加会报错，需要先复制到同一个GPU上
![](images/Pasted%20image%2020230721190906.png)

```python
import torch  
X = torch.ones(2, 3, device=torch.device('cuda'))  
Y = torch.ones(2, 3, device=torch.device('cuda:1'))
Z = X.cuda(1)
Y + Z
```
这样相加才不会报错，X+Y则会直接报错


## 神经网络与GPU

在创建神经网络模型后将其放到GPU上：
```python
from torch import nn  
  
net = nn.Sequential(nn.Linear(3, 1))  
net = net.to(device=torch.device('cuda'))  
net(X)
```

![](images/Pasted%20image%2020230721192150.png)



# 卷积神经网络
_卷积神经网络_（convolutional neural networks，CNN）是机器学习利用自然图像中一些已知结构的创造性方法。
1. _平移不变性_（translation invariance）：不管检测对象出现在图像中的哪个位置，神经网络的前面几层应该对相同的图像区域具有相似的反应，即为“平移不变性”。
2. _局部性_（locality）：神经网络的前面几层应该只探索输入图像中的局部区域，而不过度在意图像中相隔较远区域的关系，这就是“局部性”原则。最终，可以聚合这些局部特征，以在整个图像级别进行预测。
这两个原则适合于计算机视觉的神经网络架构

图像不是二维张量，而是一个由高度、宽度和颜色组成的三维张量，比如包含1024×1024×3个像素。 前两个轴与像素的空间位置有关，而第三个轴可以看作每个像素的多维表示。
由于输入图像是三维的，我们的隐藏表示H也最好采用三维张量。 换句话说，对于每一个空间位置，我们想要采用一组而不是一个隐藏表示。这样一组隐藏表示可以想象成一些互相堆叠的二维网格。 因此，我们可以把隐藏表示想象为一系列具有二维张量的**通道**（channel）。 这些通道有时也被称为**特征映射**（feature maps），因为每个通道都向后续层提供一组空间化的学习特征。 直观上可以想象在靠近输入的底层，一些通道专门识别边缘，而一些通道专门识别纹理。


我们暂时忽略通道（第三维）这一情况，看看如何处理二维图像数据和隐藏表示
![](images/Pasted%20image%2020230721201602.png)
阴影部分是第一个输出元素，以及用于计算输出的输入张量元素和核张量元素：0×0+1×1+3×2+4×3=19.
卷积窗口从输入张量的左上角开始，从左到右、从上到下滑动。 当卷积窗口滑动到新一个位置时，包含在该窗口中的部分张量与卷积核张量进行按元素相乘，得到的张量再求和得到一个单一的标量值，由此我们得出了这一位置的输出张量值



当我们添加通道时，我们的输入和隐藏的表示都变成了三维张量。例如，每个RGB输入图像具有3×ℎ×w的形状。我们将这个大小为3的轴称为**通道（channel）**维度

当输入包含多个通道时，需要构造一个与输入数据具有相同输入通道数的卷积核，以便与输入数据进行互相关运算。假设输入的通道数为$c_i$，那么卷积核的输入通道数也需要为$c_i$

由于输入和卷积核都有$c_i$个通道，我们可以对每个通道输入的二维张量和卷积核的二维张量进行互相关运算，再对通道求和（将$c_i$的结果相加）得到二维张量。这是多通道输入和多输入通道卷积核之间进行二维互相关运算的结果。


我们的机器学习任务通常会跟全局图像的问题有关（例如，“图像是否包含一只猫呢？”），所以我们最后一层的神经元应该对整个输入的全局敏感。通过逐渐聚合信息，生成越来越粗糙的映射，最终实现学习全局表示的目标，同时将卷积图层的所有优势保留在中间层。
与卷积层类似，汇聚层运算符由一个固定形状的窗口组成，该窗口根据其步幅大小在输入的所有区域上滑动，为固定形状窗口（有时称为_汇聚窗口_）遍历的每个位置计算一个输出。池运算是确定性的，我们通常计算汇聚窗口中所有元素的最大值或平均值。这些操作分别称为_最大汇聚层_（maximum pooling）和_平均汇聚层_（average pooling）
汇聚层在每个输入通道上单独运算，而不是像卷积层一样在通道上对输入进行汇总。 这意味着汇聚层的输出通道数与输入**通道数相同**

#  循环神经网络

到目前为止我们默认数据都来自于某种分布， 并且所有样本都是独立同分布的 （independently and identically distributed，i.i.d.）。 然而，大多数的数据并非如此。 例如，文章中的单词是按顺序写的，如果顺序被随机地重排，就很难理解文章原始的意思。 同样，视频中的图像帧、对话中的音频信号以及网站上的浏览行为都是有顺序的。 因此，针对此类数据而设计特定模型，可能效果会更好。

如果说卷积神经网络可以有效地处理空间信息， 那么**循环神经网络****（recurrent neural network，RNN）则可以更好地处理***序列信息***。 循环神经网络通过引入状态变量存储过去的信息和当前的输入，从而可以确定当前的输出。

### 自回归模型
第一种策略，假设在现实情况下相当长的序列可能是不必要的， 因此我们只需要满足某个长度为$\tau$的时间跨度， 即使用观测序列$x_{t-1}, \ldots, x_{t-\tau}$。 当下获得的最直接的好处就是参数的数量总是不变的， 这就使我们能够训练一个上面提及的深度网络。 这种模型被称为***自回归模型***（autoregressive models）
第二种策略，如图所示， 是保留一些对过去观测的总结$h_t$， 并且同时更新预测$\hat{x}_t$和总结$h_t$。 由于$h_t$从未被观测到，这类模型也被称为 _隐变量自回归模型_（latent autoregressive models）。
![](images/Pasted%20image%2020230722120754.png)







